{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZINA+SUvaeFOdrTk+FJuF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pakhi27/CNN-Activetion-functions-Max-Pooling-pytorch/blob/main/CNN%2CActivetion_functions_%26Max_Pooling_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ko_quZwXK-vy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import ndimage, misc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolution is a linear operation similar to a linear equation, dot product, or matrix multiplication. Convolution has several advantages for analyzing images. As discussed in the video, convolution preserves the relationship between elements, and it requires fewer parameters than other methods."
      ],
      "metadata": {
        "id": "FIa6ZUo6LPE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ ğ‘’ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›:ğ‘¦=ğ‘¤ğ‘¥+ğ‘\n",
        "\n",
        "# ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ ğ‘’ğ‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘› ğ‘¤ğ‘–ğ‘¡â„ ğ‘šğ‘¢ğ‘™ğ‘¡ğ‘–ğ‘ğ‘™ğ‘’ ğ‘£ğ‘ğ‘Ÿğ‘–ğ‘ğ‘ğ‘™ğ‘’ğ‘  ğ‘¤â„ğ‘’ğ‘Ÿğ‘’ ğ± ğ‘–ğ‘  ğ‘ ğ‘£ğ‘’ğ‘ğ‘¡ğ‘œğ‘Ÿ ğ²=ğ°ğ±+ğ‘\n",
        "#  ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥ ğ‘šğ‘¢ğ‘™ğ‘¡ğ‘–ğ‘ğ‘™ğ‘–ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘› ğ‘¤â„ğ‘’ğ‘Ÿğ‘’ ğ— ğ‘–ğ‘› ğ‘ ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥ ğ²=ğ°ğ—+ğ›\n",
        "#  ğ‘ğ‘œğ‘›ğ‘£ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘› ğ‘¤â„ğ‘’ğ‘Ÿğ‘’ ğ— ğ‘ğ‘›ğ‘‘ ğ˜ ğ‘–ğ‘  ğ‘ ğ‘¡ğ‘’ğ‘›ğ‘ ğ‘œğ‘Ÿ ğ˜=ğ°âˆ—ğ—+ğ›\n",
        "# In convolution, the parameter w is called a kernel. You can perform convolution on images where you let the variable image denote the variable X and w denote the parameter.\n"
      ],
      "metadata": {
        "id": "JkHC7KzgLVq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a two-dimensional convolution object by using the constructor Conv2d, the parameter in_channels and out_channels will be used for this section, and the parameter kernel_size will be three.\n",
        "conv = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=3)\n",
        "conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HkufRkZLaPw",
        "outputId": "deef7d8e-b2d2-4378-e50c-52edf70161ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Because the parameters in nn.Conv2d are randomly initialized and learned through training, give them some values."
      ],
      "metadata": {
        "id": "W-RoLfxXLvqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv.state_dict()['weight'][0][0]=torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0.0,-1.0]])\n",
        "conv.state_dict()['bias'][0]=0.0\n",
        "conv.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgMVTUrcLytz",
        "outputId": "9563694d-e14a-4f60-971e-1130776c7997"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[[[ 1.,  0., -1.],\n",
              "                        [ 2.,  0., -2.],\n",
              "                        [ 1.,  0., -1.]]]])),\n",
              "             ('bias', tensor([0.]))])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The shape of the image is (1,1,5,5) where:\n",
        "\n",
        "# (number of inputs, number of channels, number of rows, number of columns )\n",
        "image=torch.zeros(1,1,5,5)\n",
        "image[0,0,:,2]=1\n",
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCtnMQ2JL2lk",
        "outputId": "e8e116c5-f7a2-441f-9a5a-0dc00ab4d98a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the object conv on the tensor image as an input to perform the convolution and assign the result to the tensor z.\n",
        "z=conv(image)\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V8XAuyDMAnz",
        "outputId": "d476be6b-b032-4c01-ea9f-b9d99807d127"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-4.,  0.,  4.],\n",
              "          [-4.,  0.,  4.],\n",
              "          [-4.,  0.,  4.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determining the Size of the output\n",
        "K=2\n",
        "conv1 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=K)\n",
        "conv1.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
        "conv1.state_dict()['bias'][0]=0.0\n",
        "conv1.state_dict()\n",
        "conv1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4n7pvy3MInE",
        "outputId": "4b62a8f7-8837-4624-e166-8c9e62ad9040"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 1, kernel_size=(2, 2), stride=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an image of size 2:\n",
        "M=4\n",
        "image1=torch.ones(1,1,M,M)"
      ],
      "metadata": {
        "id": "7LEonzcdMRNq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1=conv1(image1)\n",
        "print(\"z1:\",z1)\n",
        "print(\"shape:\",z1.shape[2:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SruuIU1AMWGa",
        "outputId": "597a92bd-91eb-4ccc-a456-34f3746fe59e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z1: tensor([[[[4., 4., 4.],\n",
            "          [4., 4., 4.],\n",
            "          [4., 4., 4.]]]], grad_fn=<ConvolutionBackward0>)\n",
            "shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stride parameter\n",
        "# ğ‘€ğ‘›ğ‘’ğ‘¤=ğ‘€âˆ’ğ¾/ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘‘ğ‘’+1"
      ],
      "metadata": {
        "id": "dZqQ2lJ-MeRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolution object with a stride of 2:\n",
        "conv3 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=2)\n",
        "\n",
        "conv3.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
        "conv3.state_dict()['bias'][0]=0.0\n",
        "conv3.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yjrF3uYMlfm",
        "outputId": "87144949-0d69-4555-97ab-a83547c962af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[[[1., 1.],\n",
              "                        [1., 1.]]]])),\n",
              "             ('bias', tensor([0.]))])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For an image with a size of 4, calculate the output size:\n",
        "\n",
        "# ğ‘€ğ‘›ğ‘’ğ‘¤=ğ‘€âˆ’ğ¾ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘‘ğ‘’+1\n",
        "\n",
        "# ğ‘€ğ‘›ğ‘’ğ‘¤=4âˆ’22+1\n",
        "\n",
        "# ğ‘€ğ‘›ğ‘’ğ‘¤=2"
      ],
      "metadata": {
        "id": "vGL_92zwMxyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z3=conv3(image1)\n",
        "\n",
        "print(\"z3:\",z3)\n",
        "print(\"shape:\",z3.shape[2:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpRYxxrBM-9m",
        "outputId": "d358514d-a9a8-4649-a6c5-d7f5d7c909ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z3: tensor([[[[4., 4.],\n",
            "          [4., 4.]]]], grad_fn=<ConvolutionBackward0>)\n",
            "shape: torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero Padding Â¶"
      ],
      "metadata": {
        "id": "L4ArCf0CNBVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As you apply successive convolutions, the image will shrink. You can apply zero padding to keep the image at a reasonable size, which also holds information at the borders.\n",
        "\n",
        "# In addition, you might not get integer values for the size of the kernel. Consider the following image:\n",
        "image1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmsBIz4BNCLX",
        "outputId": "b5c93966-3079-404f-e8e8-2c3af607ff3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv4 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=3)\n",
        "conv4.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
        "conv4.state_dict()['bias'][0]=0.0\n",
        "conv4.state_dict()\n",
        "z4=conv4(image1)\n",
        "print(\"z4:\",z4)\n",
        "print(\"z4:\",z4.shape[2:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiusT3frNGm3",
        "outputId": "516338ed-062b-4263-acda-d40d0f549a45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z4: tensor([[[[4.]]]], grad_fn=<ConvolutionBackward0>)\n",
            "z4: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv5 = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=2,stride=3,padding=1)\n",
        "\n",
        "conv5.state_dict()['weight'][0][0]=torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
        "conv5.state_dict()['bias'][0]=0.0\n",
        "conv5.state_dict()\n",
        "z5=conv5(image1)\n",
        "print(\"z5:\",z5)\n",
        "print(\"z5:\",z4.shape[2:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NybnN9dBNR8f",
        "outputId": "bbd12d1b-515c-4936-d050-f964657667d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z5: tensor([[[[1., 2.],\n",
            "          [2., 4.]]]], grad_fn=<ConvolutionBackward0>)\n",
            "z5: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation Functions"
      ],
      "metadata": {
        "id": "6Gv3Vfg4Q55x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import ndimage, misc"
      ],
      "metadata": {
        "id": "6F190s6WQ8Y1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a kernel and image as usual. Set the bias to zero:\n",
        "conv = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=3)\n",
        "Gx=torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0,-1.0]])\n",
        "conv.state_dict()['weight'][0][0]=Gx\n",
        "conv.state_dict()['bias'][0]=0.0\n",
        "conv.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bihh2xIERAmx",
        "outputId": "891c5ba5-d651-40f3-d15c-553b304daf71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[[[ 1.,  0., -1.],\n",
              "                        [ 2.,  0., -2.],\n",
              "                        [ 1.,  0., -1.]]]])),\n",
              "             ('bias', tensor([0.]))])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image=torch.zeros(1,1,5,5)\n",
        "image[0,0,:,2]=1\n",
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Om--ifRELf",
        "outputId": "bde8cd4f-f4aa-4a87-d429-cccee846d260"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z=conv(image)\n",
        "Z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh8fEI_QRHHH",
        "outputId": "69839438-2c2e-4631-9132-8d2c31c0ac12"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-4.,  0.,  4.],\n",
              "          [-4.,  0.,  4.],\n",
              "          [-4.,  0.,  4.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A=torch.relu(Z)\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx5iJmOjRJYh",
        "outputId": "8ff2e2b1-59ee-4018-921b-1f4348f329ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 4.],\n",
              "          [0., 0., 4.],\n",
              "          [0., 0., 4.]]]], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relu = nn.ReLU()\n",
        "relu(Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M316r9wGRLZ4",
        "outputId": "bd17f928-52e4-4fa8-9adf-e44f4f5828e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 4.],\n",
              "          [0., 0., 4.],\n",
              "          [0., 0., 4.]]]], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max Pooling\n"
      ],
      "metadata": {
        "id": "GVANoJzFRP_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image1=torch.zeros(1,1,4,4)\n",
        "image1[0,0,0,:]=torch.tensor([1.0,2.0,3.0,-4.0])\n",
        "image1[0,0,1,:]=torch.tensor([0.0,2.0,-3.0,0.0])\n",
        "image1[0,0,2,:]=torch.tensor([0.0,2.0,3.0,1.0])\n",
        "\n",
        "image1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE5AvTA3RROW",
        "outputId": "05a7fe33-8aad-4f1f-fbb7-ee6285c51d7f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.,  2.,  3., -4.],\n",
              "          [ 0.,  2., -3.,  0.],\n",
              "          [ 0.,  2.,  3.,  1.],\n",
              "          [ 0.,  0.,  0.,  0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Max pooling simply takes the maximum value in each region."
      ],
      "metadata": {
        "id": "wdAgqzbPRUik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a maxpooling object in 2d as follows and perform max pooling as follows:\n",
        "max1=torch.nn.MaxPool2d(2,stride=1)\n",
        "max1(image1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_fam2DIRVPH",
        "outputId": "19d313cd-5929-4977-b53a-26953d4d01f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[2., 3., 3.],\n",
              "          [2., 3., 3.],\n",
              "          [2., 3., 3.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max1=torch.nn.MaxPool2d(2)\n",
        "max1(image1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNmX4HgTRZ5S",
        "outputId": "8ff242a3-c1ce-4051-f895-c39806e77e27"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[2., 3.],\n",
              "          [2., 3.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}